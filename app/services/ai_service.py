import logging
import asyncio
import json
from typing import Dict, List
from app.core.config import settings


logger = logging.getLogger(__name__)


class AIService:
    """OpenAI GPTë¥¼ í™œìš©í•œ AI ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ìƒˆë¡œìš´ ë°©ì‹)
        try:
            from openai import AsyncOpenAI
            self.client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)
        except ImportError:
            # êµ¬ë²„ì „ openai íŒ¨í‚¤ì§€ ëŒ€ì‘
            import openai
            openai.api_key = settings.OPENAI_API_KEY
            self.client = None
            
        # ëª¨ë¸ëª… ì„¤ì •
        self.model_name = getattr(settings, "OPENAI_MODEL", "gpt-3.5-turbo")
        
    async def summarize_content(self, content: str, title: str = "", url: str = "") -> Dict:
        """ì»¨í…ì¸  ìš”ì•½ ë° íƒœê·¸ ìƒì„±"""
        
        # í† í° ì œí•œì„ ìœ„í•œ ë‚´ìš© ì˜ë¼ë‚´ê¸°
        content_truncated = content[:4000] if len(content) > 4000 else content
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self._create_summary_prompt(title, content_truncated, url)
        
        try:
            if self.client:
                # ìƒˆë¡œìš´ OpenAI í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©
                response = await self.client.chat.completions.create(
                    model=self.model_name,
                    messages=[
                        {
                            "role": "system", 
                            "content": "ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ì½˜í…ì¸  íë ˆì´í„°ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë‚´ìš©ì„ ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ë©°, ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."
                        },
                        {
                            "role": "user", 
                            "content": prompt
                        }
                    ],
                    max_tokens=600,
                    temperature=0.3,
                )
            else:
                # êµ¬ë²„ì „ openai íŒ¨í‚¤ì§€ ëŒ€ì‘
                import openai
                response = await openai.ChatCompletion.acreate(
                    model=self.model_name,
                    messages=[
                        {
                            "role": "system", 
                            "content": "ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ì½˜í…ì¸  íë ˆì´í„°ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë‚´ìš©ì„ ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ë©°, ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."
                        },
                        {
                            "role": "user", 
                            "content": prompt
                        }
                    ],
                    max_tokens=600,
                    temperature=0.3,
                )
            
            # ì‘ë‹µ íŒŒì‹±
            ai_response = response.choices[0].message.content
            parsed_result = self._parse_ai_response(ai_response)
            
            return {
                "summary": parsed_result["summary"],
                "tags": parsed_result["tags"],
                "success": True,
                "token_used": response.usage.total_tokens
            }
            
        except Exception as e:
            logger.error(f"AI ìš”ì•½ ì‹¤íŒ¨: {e}")
            return {
                "error": f"AI ìš”ì•½ ì‹¤íŒ¨: {str(e)}",
                "success": False
            }
    
    async def generate_response(self, prompt: str) -> Dict:
        """
        RAG ì‹œìŠ¤í…œìš© í…ìŠ¤íŠ¸ ìƒì„±
        ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ë¡œ OpenAI GPT ëª¨ë¸ ì‘ë‹µ ìƒì„±
        """
        try:
            if self.client:
                # ìƒˆë¡œìš´ OpenAI í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©
                response = await self.client.chat.completions.create(
                    model=self.model_name,
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ê°œì¸ ì§€ì‹ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=1000,
                    temperature=0.7
                )
            else:
                # êµ¬ë²„ì „ openai íŒ¨í‚¤ì§€ ëŒ€ì‘
                import openai
                response = await openai.ChatCompletion.acreate(
                    model=self.model_name,
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ê°œì¸ ì§€ì‹ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=1000,
                    temperature=0.7
                )
            
            return {
                "success": True,
                "response": response.choices[0].message.content,
                "usage": {
                    "prompt_tokens": response.usage.prompt_tokens,
                    "completion_tokens": response.usage.completion_tokens,
                    "total_tokens": response.usage.total_tokens
                }
            }
            
        except Exception as e:
            logger.error(f"AI ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e)
            }

    async def answer_question(self, question: str, context: str) -> Dict:
        """ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€ (RAGìš©)"""
        
        prompt = f"""ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ê°œì¸ ì§€ì‹ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì‚¬ìš©ìê°€ ì €ì¥í•œ ì»¨í…ì¸  ê¸°ë°˜ ì •ë³´:
{context}

ì‚¬ìš©ì ì§ˆë¬¸: {question}

ìœ„ì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
- ì œê³µëœ ì •ë³´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”
- ì—†ëŠ” ì •ë³´ëŠ” ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”
- êµ¬ì²´ì ì´ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”"""
        
        try:
            logger.info(f"ğŸ¤– RAG ì§ˆë‹µ ì‹œì‘: question='{question[:50]}...'")
            
            if self.client:
                # ìƒˆë¡œìš´ OpenAI í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©
                response = await self.client.chat.completions.create(
                    model=self.model_name,
                    messages=[
                        {
                            "role": "system",
                            "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ê°œì¸ ì§€ì‹ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì œê³µëœ ì •ë³´ë§Œ ì‚¬ìš©í•˜ì—¬ ì •í™•í•˜ê²Œ ë‹µë³€í•©ë‹ˆë‹¤."
                        },
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    max_tokens=500,
                    temperature=0.7
                )
            else:
                # êµ¬ë²„ì „ openai íŒ¨í‚¤ì§€ ëŒ€ì‘
                import openai
                response = await openai.ChatCompletion.acreate(
                    model=self.model_name,
                    messages=[
                        {
                            "role": "system",
                            "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ê°œì¸ ì§€ì‹ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì œê³µëœ ì •ë³´ë§Œ ì‚¬ìš©í•˜ì—¬ ì •í™•í•˜ê²Œ ë‹µë³€í•©ë‹ˆë‹¤."
                        },
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    max_tokens=500,
                    temperature=0.7
                )
            
            answer = response.choices[0].message.content.strip()
            logger.info(f"âœ… RAG ì§ˆë‹µ ì™„ë£Œ: {answer[:50]}...")
            
            return {
                "success": True,
                "answer": answer,
                "token_used": response.usage.total_tokens
            }
            
        except Exception as e:
            logger.error(f"âŒ RAG ì§ˆë‹µ ì‹¤íŒ¨: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "answer": ""
            }
    
    def _create_summary_prompt(self, title: str, content: str, url: str) -> str:
        """ìš”ì•½ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return f"""
ë‹¤ìŒ ì›¹ ì»¨í…ì¸ ë¥¼ ë¶„ì„í•˜ì—¬ í•œêµ­ì–´ë¡œ ìš”ì•½í•˜ê³  íƒœê·¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.


ì œëª©: {title}
URL: {url}
ë‚´ìš©:
{content}


ìš”ì²­ì‚¬í•­:
1. í•µì‹¬ ë‚´ìš©ì„ 3-4ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½
2. ê´€ë ¨ í‚¤ì›Œë“œ/íƒœê·¸ 5ê°œ ì´í•˜ ì¶”ì¶œ (í•œêµ­ì–´)
3. ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:


ìš”ì•½: [ì—¬ê¸°ì— ìš”ì•½ ë‚´ìš©]
íƒœê·¸: [íƒœê·¸1, íƒœê·¸2, íƒœê·¸3, íƒœê·¸4, íƒœê·¸5]


ì£¼ì˜ì‚¬í•­:
- ì •í™•í•œ ì •ë³´ë§Œ í¬í•¨
- ê´‘ê³ ì„± ë‚´ìš© ì œì™¸
- ê°ê´€ì  ê´€ì  ìœ ì§€
"""
    
    def _parse_ai_response(self, response: str) -> Dict:
        """AI ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ ìš”ì•½ê³¼ íƒœê·¸ ë¶„ë¦¬"""
        try:
            lines = response.strip().split('\n')
            summary = ""
            tags = []
            
            for line in lines:
                line = line.strip()
                if line.startswith('ìš”ì•½:'):
                    summary = line.replace('ìš”ì•½:', '').strip()
                elif line.startswith('íƒœê·¸:'):
                    tag_text = line.replace('íƒœê·¸:', '').strip()
                    # íƒœê·¸ íŒŒì‹±: "[íƒœê·¸1, íƒœê·¸2]" ë˜ëŠ” "íƒœê·¸1, íƒœê·¸2" í˜•ì‹ ì²˜ë¦¬
                    tag_text = tag_text.strip('[]')
                    tags = [tag.strip() for tag in tag_text.split(',') if tag.strip()]
            
            return {
                "summary": summary if summary else "ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "tags": tags[:5]  # ìµœëŒ€ 5ê°œ íƒœê·¸ë§Œ
            }
            
        except Exception:
            # íŒŒì‹± ì‹¤íŒ¨ì‹œ ì „ì²´ ì‘ë‹µì„ ìš”ì•½ìœ¼ë¡œ ì‚¬ìš©
            return {
                "summary": response[:500] if len(response) > 500 else response,
                "tags": []
            }

    async def generate_tags_only(self, title: str, summary: str) -> List[str]:
        """ìš”ì•½ëœ ë‚´ìš©ìœ¼ë¡œë¶€í„° íƒœê·¸ë§Œ ìƒì„±"""
        prompt = f"""
ì œëª©: {title}
ìš”ì•½: {summary}


ìœ„ ë‚´ìš©ê³¼ ê´€ë ¨ëœ í•œêµ­ì–´ í‚¤ì›Œë“œ 5ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
í˜•ì‹: í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2, í‚¤ì›Œë“œ3, í‚¤ì›Œë“œ4, í‚¤ì›Œë“œ5
"""
        
        try:
            if self.client:
                response = await self.client.chat.completions.create(
                    model=self.model_name,
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=100,
                    temperature=0.3
                )
            else:
                import openai
                response = await openai.ChatCompletion.acreate(
                    model=self.model_name,
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=100,
                    temperature=0.3
                )
            
            tags_text = response.choices[0].message.content.strip()
            tags = [tag.strip() for tag in tags_text.split(',')]
            return tags[:5]
            
        except Exception as e:
            logger.error(f"íƒœê·¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return ["ì¼ë°˜"]
